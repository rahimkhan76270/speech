{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"/mnt/d/Programs/Python/PW/projects/asteroid/zip-hindi-2k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn as nn   \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from numpy.random import choice\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=glob(f\"{data_dir}/**/*.wav\")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE=16_000\n",
    "SEG_LENGTH=0.63\n",
    "NUM_FBANK=64\n",
    "WINDOW_LENGTH=0.025\n",
    "OVERLAP=0.010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prologue(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=1,\n",
    "                 out_channels=128,\n",
    "                 kernel_size=11,):\n",
    "        super(Prologue,self).__init__()\n",
    "        self.prolog=nn.Conv2d(in_channels=in_channels,\n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              padding='same')\n",
    "        self.norm1=nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu=nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.prolog(x)\n",
    "        x=self.norm1(x)\n",
    "        x=self.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuartzSubBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size) -> None:\n",
    "        super(QuartzSubBlock,self).__init__()\n",
    "        self.depthwise_conv = nn.Conv2d(out_channels,\n",
    "                                        out_channels,\n",
    "                                        kernel_size=kernel_size, \n",
    "                                        padding=kernel_size//2, \n",
    "                                        groups=out_channels)\n",
    "        self.pointwise_conv = nn.Conv2d(in_channels, \n",
    "                                        out_channels, \n",
    "                                        kernel_size=1)\n",
    "        self.norm=nn.BatchNorm2d(out_channels)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout=nn.Dropout()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.pointwise_conv(x)\n",
    "        x=self.depthwise_conv(x)\n",
    "        x=self.norm(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.dropout(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuartzBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 num_sub_blocks=2):\n",
    "        super(QuartzBlock,self).__init__()\n",
    "        self.sub_block_list=[QuartzSubBlock(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size\n",
    "        ) for _ in range(num_sub_blocks)]\n",
    "        self.sub_blocks=nn.Sequential(*self.sub_block_list)\n",
    "        self.depthwise_conv1 = nn.Conv2d(out_channels,\n",
    "                                        out_channels,\n",
    "                                        kernel_size=kernel_size, \n",
    "                                        padding=kernel_size//2, \n",
    "                                        groups=out_channels)\n",
    "        self.pointwise_conv1 = nn.Conv2d(out_channels, \n",
    "                                        out_channels, \n",
    "                                        kernel_size=1)\n",
    "        self.norm1=nn.BatchNorm2d(out_channels)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.dropout1=nn.Dropout()\n",
    "        self.pointwise_conv2 = nn.Conv2d(out_channels, \n",
    "                                        out_channels, \n",
    "                                        kernel_size=1)\n",
    "        self.norm2=nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y=self.sub_blocks(x)\n",
    "        y=self.pointwise_conv1(x)\n",
    "        y=self.depthwise_conv1(x)\n",
    "        y=self.norm1(y)\n",
    "        x=self.pointwise_conv2(x)\n",
    "        x=self.norm2(x)\n",
    "        out=self.relu1(x+y)\n",
    "        out=self.dropout1(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Epilogue(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 dilation=1):\n",
    "        super(Epilogue,self).__init__()\n",
    "        self.conv=nn.Conv2d(in_channels=in_channels,\n",
    "                            out_channels=out_channels,\n",
    "                            kernel_size=kernel_size,\n",
    "                            dilation=dilation)\n",
    "        self.norm=nn.BatchNorm2d(out_channels)\n",
    "        self.relu=nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.conv(x)\n",
    "        x=self.norm(x)\n",
    "        x=self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarbleNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(MarbleNet,self).__init__()\n",
    "        self.prolog=Prologue()\n",
    "        self.resizer=nn.Conv2d(in_channels=128,out_channels=64,kernel_size=1)\n",
    "        self.block_b1=QuartzBlock(out_channels=64,\n",
    "                                  kernel_size=13,\n",
    "                                  num_sub_blocks=2)\n",
    "        self.block_b2=QuartzBlock(out_channels=64,\n",
    "                                  kernel_size=15,\n",
    "                                  num_sub_blocks=2)\n",
    "        self.block_b3=QuartzBlock(out_channels=64,\n",
    "                                  kernel_size=17,\n",
    "                                  num_sub_blocks=2)\n",
    "        self.epilogue1=Epilogue(in_channels=64,\n",
    "                                out_channels=128,\n",
    "                                kernel_size=29,\n",
    "                                dilation=2)\n",
    "        self.epilogue2=Epilogue(in_channels=128,\n",
    "                                out_channels=128,\n",
    "                                kernel_size=1)\n",
    "        self.conv1x1=nn.Conv2d(in_channels=128,\n",
    "                            out_channels=2,\n",
    "                            kernel_size=1)\n",
    "        self.linear=nn.Linear(in_features=128,out_features=2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.prolog(x)\n",
    "        x=self.resizer(x)\n",
    "        x=self.block_b1(x)\n",
    "        x=self.block_b2(x)\n",
    "        x=self.block_b3(x)\n",
    "        x=self.epilogue1(x)\n",
    "        x=self.epilogue2(x)\n",
    "        x=self.conv1x1(x)\n",
    "        batch=x.shape[0]\n",
    "        x=torch.reshape(x,shape=(batch,-1))\n",
    "        x=self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarbleNetDataset(Dataset):\n",
    "    def __init__(self,audio_files,\n",
    "                 noise_files,\n",
    "                 sample_rate=16_000,\n",
    "                 seg_len=0.63,\n",
    "                 num_filts=64,\n",
    "                 win_len=0.025,\n",
    "                 overlap=0.01):\n",
    "        self.audio_files=audio_files\n",
    "        self.noise_files=noise_files\n",
    "        self.sample_rate=sample_rate\n",
    "        self.seg_len=int(seg_len*sample_rate)\n",
    "        self.num_filts=num_filts\n",
    "        self.win_len=int(win_len*sample_rate)\n",
    "        self.overlap=int(overlap*sample_rate)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)+len(self.noise_files)\n",
    "    \n",
    "    def __getitem__(self):\n",
    "        chance=torch.rand(1).item()\n",
    "        file=None\n",
    "        label=None\n",
    "        if chance > 0.5:\n",
    "            file=choice(self.audio_files,1).item()\n",
    "            label=1\n",
    "        else:\n",
    "            file=choice(self.noise_files,1).item()\n",
    "            label=0\n",
    "        data,_=librosa.load(file,sr=self.sample_rate,mono=True)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=data, sr=self.sample_rate, \n",
    "                                                         n_fft=512,\n",
    "                                                         hop_length=self.overlap, \n",
    "                                                         win_length=self.win_len, \n",
    "                                                         n_mels=self.num_filts)\n",
    "        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "        if mel_spectrogram_db.shape[1] > 64:\n",
    "            mel_spectrogram_db = mel_spectrogram_db[:, :64]\n",
    "        elif mel_spectrogram_db.shape[1] < 64:\n",
    "            mel_spectrogram_db = np.pad(mel_spectrogram_db, ((0, 0), (0, 64 - mel_spectrogram_db.shape[1])), mode='constant')\n",
    "        return torch.tensor(mel_spectrogram_db).unsqueeze(0),torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "marblenet_model=MarbleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_files=glob('/mnt/d/Programs/Python/PW/projects/asteroid/noise-2k/**/*.wav')\n",
    "len(noise_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=MarbleNetDataset(\n",
    "    audio_files=files,\n",
    "    noise_files=noise_files\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader=DataLoader(dataset,batch_size=3,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.SGD(marblenet_model.parameters(),lr=0.01,momentum=0.9,weight_decay=0.001)\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "marblenet_model=marblenet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    marblenet_model.train()\n",
    "    train_loss=0\n",
    "    for x,y in dataloader:\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output=marblenet_model(x)\n",
    "        loss=criterion(output,y)\n",
    "        train_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch: {epoch} loss: {train_loss/len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(marblenet_model,'./marble_net.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
