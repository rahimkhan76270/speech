{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_speaker_pytorch.triplet_loss import DeepSpeakerLoss\n",
    "from deep_speaker_pytorch.batcher import DeepSpeakerTripletDataset,LazyTripletBatcher,KerasFormatConverter\n",
    "from deep_speaker_pytorch.model import DeepSpeaker\n",
    "from deep_speaker_pytorch.audio import Audio\n",
    "from deep_speaker_pytorch.utils import train_test_sp_to_utt,load_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn   \n",
    "import torch.nn.functional as F\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DeepSpeaker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIEMSimilarity(nn.Module):\n",
    "    def __init__(self,v_m=-1,v_M=1):\n",
    "        super(DIEMSimilarity,self).__init__()\n",
    "        self.dq=deque(maxlen=1000)\n",
    "        self.v_M=v_M\n",
    "        self.v_m=v_m\n",
    "        self.ed=None\n",
    "        self.var=None\n",
    "    \n",
    "    def forward(self,batch1:torch.tensor,batch2:torch.tensor)->torch.tensor:\n",
    "        for v1,v2 in zip(batch1,batch2):\n",
    "            self.dq.append(v1.tolist())\n",
    "            self.dq.append(v2.tolist())\n",
    "        t=torch.tensor(list(self.dq))\n",
    "        self.var=t.var()\n",
    "        pdist=F.pdist(t)\n",
    "        self.ed=pdist.mean()\n",
    "        # self.v_M=t.max()\n",
    "        # self.v_m=t.min()\n",
    "        batch_diem=(self.v_M-self.v_m)*(torch.linalg.vector_norm(batch1-batch2,ord=2,axis=1)-self.ed)/self.var\n",
    "        return torch.sum(batch_diem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio=Audio(cache_dir='/mnt/d/Programs/Python/PW/projects/speech/embeddings/working_dir',\n",
    "            audio_dir='/mnt/c/Users/rahim/Downloads/archive/data',\n",
    "            sample_rate=16_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc=KerasFormatConverter('/mnt/d/Programs/Python/PW/projects/speech/embeddings/working_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc.persist_to_disk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_speakers=load_pickle('/mnt/d/Programs/Python/PW/projects/speech/embeddings/working_dir/keras-inputs/categorical_speakers.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_speakers.get_index('0001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing the batcher:   0%|          | 0/4 [00:00<?, ?it/s]/mnt/d/Programs/Python/PW/projects/speech/speech_env_torch/lib/python3.12/site-packages/deep_speaker_pytorch/batcher.py:129: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  model_inputs=torch.tensor(model_inputs,device=self.device).float()\n",
      "Initializing the batcher: 100%|██████████| 4/4 [00:24<00:00,  6.07s/it]\n"
     ]
    }
   ],
   "source": [
    "batcher=LazyTripletBatcher('/mnt/d/Programs/Python/PW/projects/speech/embeddings/working_dir',\n",
    "                           160,model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.5870, -0.5787, -0.5728,  ..., -0.3908, -0.3095, -0.4094],\n",
       "           [-0.5102, -0.5111, -0.4948,  ..., -0.4717, -0.4672, -0.4985],\n",
       "           [-0.4439, -0.4402, -0.4240,  ..., -0.4165, -0.4145, -0.4322],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       " \n",
       " \n",
       "         [[[-0.5457, -0.5456, -0.5456,  ...,  0.5854,  0.3795, -0.2786],\n",
       "           [-0.5872, -0.5874, -0.5874,  ...,  0.7210,  1.4015, -0.2068],\n",
       "           [-0.7530, -0.7513, -0.7539,  ...,  0.6355,  1.5747, -0.1326],\n",
       "           ...,\n",
       "           [-0.2306, -0.1067, -0.1617,  ..., -0.5332, -0.5346, -0.5438],\n",
       "           [-0.6845, -0.6551, -0.5847,  ..., -0.6692, -0.6799, -0.6838],\n",
       "           [-0.5502, -0.5156, -0.3960,  ..., -0.5562, -0.5666, -0.5686]]],\n",
       " \n",
       " \n",
       "         [[[-0.0684,  2.9339,  0.0871,  ..., -0.0715, -0.0656, -0.4948],\n",
       "           [-0.9476, -0.7583, -0.9004,  ..., -0.9253, -0.9483, -0.9551],\n",
       "           [-0.6059, -0.6249, -0.6297,  ..., -0.6528, -0.6598, -0.6604],\n",
       "           ...,\n",
       "           [-0.6410, -0.6500, -0.2832,  ..., -0.6264, -0.6229, -0.6708],\n",
       "           [-0.7469, -0.8331,  0.0948,  ..., -0.7662, -0.7322, -0.8182],\n",
       "           [-0.7265, -0.7708,  0.6659,  ..., -0.7361, -0.6786, -0.7480]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 7.0737,  2.3668,  1.2923,  ..., -0.0240,  0.3156, -0.0450],\n",
       "           [-0.6060, -0.5320, -0.6038,  ...,  0.4718,  0.4947,  0.0689],\n",
       "           [-0.4954, -0.5011, -0.5116,  ...,  0.3195,  0.2031, -0.1210],\n",
       "           ...,\n",
       "           [-0.5119, -0.5111, -0.5260,  ..., -0.4905, -0.4622, -0.5202],\n",
       "           [-0.4546, -0.4811, -0.4744,  ..., -0.3901, -0.3840, -0.4808],\n",
       "           [-0.3721, -0.3404, -0.3393,  ..., -0.3115, -0.3217, -0.3832]]],\n",
       " \n",
       " \n",
       "         [[[-0.7220, -0.7259, -0.7245,  ...,  1.6388,  0.4972, -0.2120],\n",
       "           [-1.0570, -1.0348, -1.0473,  ...,  1.4234,  0.2220, -0.5265],\n",
       "           [-0.6604, -0.6664, -0.6631,  ..., -0.5519, -0.6030, -0.6635],\n",
       "           ...,\n",
       "           [-0.1879, -0.2378, -0.2938,  ..., -0.3025, -0.3019, -0.3022],\n",
       "           [-0.2746, -0.2856, -0.3107,  ..., -0.3111, -0.3103, -0.3110],\n",
       "           [-0.3029, -0.2867, -0.2810,  ..., -0.3165, -0.3160, -0.3160]]],\n",
       " \n",
       " \n",
       "         [[[-0.5228, -0.5158, -0.5209,  ..., -0.5181, -0.5135, -0.5184],\n",
       "           [-0.4635, -0.4431, -0.3996,  ..., -0.4364, -0.4124, -0.4351],\n",
       "           [-0.4937, -0.8395, -0.4707,  ..., -0.1374,  0.3806,  0.3030],\n",
       "           ...,\n",
       "           [-0.4434, -0.4423, -0.4404,  ...,  0.5973,  0.4924, -0.2806],\n",
       "           [-0.4838, -0.4835, -0.4837,  ...,  2.7471,  1.8604,  0.0585],\n",
       "           [-0.4486, -0.4485, -0.4487,  ...,  3.2542,  2.8826, -0.0086]]]]),\n",
       " tensor([[63.],\n",
       "         [93.],\n",
       "         [47.],\n",
       "         [63.],\n",
       "         [93.],\n",
       "         [47.],\n",
       "         [35.],\n",
       "         [92.],\n",
       "         [41.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batcher.get_random_batch(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
