{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 08:04:33.988403: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-17 08:04:35.611260: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-17 08:04:36.136470: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-17 08:04:40.110897: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 08:05:07.712752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model,Sequential # type:ignore\n",
    "from tensorflow.keras.layers import Conv1D,PReLU,BatchNormalization,Conv1DTranspose,LayerNormalization,ReLU # type:ignore\n",
    "from tensorflow.data import Dataset # type:ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvResBlock(Model):\n",
    "    def __init__(self,\n",
    "                 in_channels=256,\n",
    "                 out_channels=512,\n",
    "                 kernel_size=3,\n",
    "                 dilation=1,\n",
    "                 causal=False):\n",
    "        super(ConvResBlock,self).__init__()\n",
    "        self.out_channels=out_channels\n",
    "        self.kernel_size=kernel_size\n",
    "        self.causal=causal\n",
    "        self.in_channels=in_channels\n",
    "        self.conv1x1=Conv1D(\n",
    "            filters=self.out_channels,\n",
    "            kernel_size=1,\n",
    "            data_format='channels_first',\n",
    "            use_bias=False\n",
    "        )\n",
    "        self.PReLU_1=PReLU(shared_axes=[2])\n",
    "        self.norm1=BatchNormalization(axis=1)\n",
    "        self.pad = (dilation * (kernel_size - 1)) // 2 if not causal else (\n",
    "            dilation * (kernel_size - 1))\n",
    "        self.dwconv=Conv1D(\n",
    "            filters=self.out_channels,\n",
    "            kernel_size=self.kernel_size,\n",
    "            groups=self.out_channels,\n",
    "            padding='same',\n",
    "            dilation_rate=dilation,\n",
    "            data_format='channels_first',\n",
    "            use_bias=False\n",
    "        )\n",
    "        self.PReLU_2=PReLU(shared_axes=[2])\n",
    "        self.norm2=BatchNormalization(axis=1)\n",
    "        self.sc_conv=Conv1D(\n",
    "            filters=self.in_channels,\n",
    "            kernel_size=1,\n",
    "            data_format='channels_first',\n",
    "            use_bias=True\n",
    "        )\n",
    "    def call(self,x):\n",
    "        c=self.conv1x1(x)\n",
    "        c=self.PReLU_1(c)\n",
    "        c=self.norm1(c)\n",
    "        c=self.dwconv(c)\n",
    "        if self.causal:\n",
    "            c=c[:,:,:-self.pad]\n",
    "        c=self.sc_conv(c)\n",
    "        return c+x\n",
    "    def build(self,input_shape):\n",
    "        super(ConvResBlock,self).build(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    def __init__(self,out_channels=512,\n",
    "                 kernel_size=16):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.out_channels=out_channels\n",
    "        self.kernel_size=kernel_size\n",
    "        self.conv1=Conv1D(filters=self.out_channels,\n",
    "                        kernel_size=self.kernel_size,\n",
    "                        strides=self.kernel_size//2,\n",
    "                        padding='valid',\n",
    "                        data_format='channels_first')\n",
    "\n",
    "    def call(self,x):\n",
    "        y=self.conv1(x)\n",
    "        return y\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        super(Encoder,self).build(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "    def __init__(self,\n",
    "                 out_channels=1,\n",
    "                 kernel_size=16,\n",
    "                 strides=8):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.conv_trans1d=Conv1DTranspose(\n",
    "            filters=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            data_format='channels_first'\n",
    "        )\n",
    "\n",
    "    def call(self,x):\n",
    "        x=self.conv_trans1d(x)\n",
    "        return x\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        super(Decoder,self).build(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialBlock(Model):\n",
    "    def __init__(self,num_blocks,**block_args):\n",
    "        super(SequentialBlock,self).__init__()\n",
    "        self.block_list=[ConvResBlock(**block_args,dilation=2**i) for i in range(num_blocks)]\n",
    "        self.seq_block=Sequential(self.block_list)\n",
    "\n",
    "    def call(self,x):\n",
    "        x=self.seq_block(x)\n",
    "        return x\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        super(SequentialBlock,self).build(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparationBlock(Model):\n",
    "    def __init__(self,num_repeat,**block_args):\n",
    "        super(SeparationBlock,self).__init__()\n",
    "        self.seq_repeat=Sequential([SequentialBlock(**block_args) for _ in range(num_repeat)])\n",
    "\n",
    "    def call(self,x):\n",
    "        x=self.seq_repeat(x)\n",
    "        return x\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        super(SeparationBlock,self).build(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTasNet(Model):\n",
    "    def __init__(self,\n",
    "                 N=512,\n",
    "                 L=16,\n",
    "                 B=128,\n",
    "                 H=512,\n",
    "                 P=3,\n",
    "                 X=8,\n",
    "                 R=3,\n",
    "                 num_spks=2,\n",
    "                 causal=False):\n",
    "        super(ConvTasNet,self).__init__()\n",
    "        self.encoder=Encoder(\n",
    "            out_channels=N,\n",
    "            kernel_size=L\n",
    "        )\n",
    "        self.layer_norm=LayerNormalization(axis=1)\n",
    "        self.bottle_neck=Conv1D(\n",
    "            filters=B,\n",
    "            kernel_size=1,\n",
    "            data_format='channels_first'\n",
    "        )\n",
    "        self.separation=SeparationBlock(\n",
    "            num_repeat=R,\n",
    "            num_blocks=X,\n",
    "            in_channels=B,\n",
    "            out_channels=H,\n",
    "            kernel_size=P,\n",
    "            causal=causal\n",
    "        )\n",
    "        self.gen_masks=Conv1D(\n",
    "            filters=N*num_spks,\n",
    "            kernel_size=1,\n",
    "            data_format='channels_first'\n",
    "        )\n",
    "        self.decoder=Decoder(out_channels=1,\n",
    "                             kernel_size=L,\n",
    "                             strides=L//2)\n",
    "        self.activation=ReLU()\n",
    "        self.num_spks=num_spks\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        super(ConvTasNet,self).build(input_shape)\n",
    "    def call(self,x):\n",
    "        # print(\"shape x\",x.shape)\n",
    "        w=self.encoder(x)\n",
    "        # print(\"shape encoder\",w.shape)\n",
    "        e=self.layer_norm(w)\n",
    "        # print(\"shape layer norm\",e.shape)\n",
    "        e=self.bottle_neck(e)\n",
    "        # print(\"shape bottle neck\",e.shape)\n",
    "        e=self.separation(e)\n",
    "        # print(\"shape separation\",e.shape)\n",
    "        m=self.gen_masks(e)\n",
    "        # print(\"shape gen mask\",m.shape)\n",
    "        m=tf.split(m,num_or_size_splits=self.num_spks,axis=1)\n",
    "        m=self.activation(tf.stack(m,axis=0))\n",
    "        d=[w*m[i] for i in range(self.num_spks)]\n",
    "        s=[self.decoder(d[i]) for i in range(self.num_spks)]\n",
    "        return tf.stack(s,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTasNetDataGenerator:\n",
    "    \"\"\"\n",
    "    audio sample rate should be same as passed in the class there is no auto conversion done in this class\n",
    "    \"\"\"\n",
    "    def __init__(self,folder_path:str,\n",
    "                 audio_chunk_len=2,\n",
    "                 num_spks=2,\n",
    "                sample_rate=8_000,\n",
    "                data_len=1000,\n",
    "                file_ext='wav'):\n",
    "        self.all_files=glob(f\"{folder_path}/*.{file_ext}\")\n",
    "        self.data_len=len(self.all_files)\n",
    "        self.sample_rate=sample_rate\n",
    "        self.num_spks=num_spks\n",
    "        self.audio_chunk_len=audio_chunk_len\n",
    "        self.audio_with_start_end=self.load_files()\n",
    "        self.data_len=data_len\n",
    "\n",
    "    def load_files(self):\n",
    "        files=[]\n",
    "        for file in self.all_files:\n",
    "            info=sf.info(file)\n",
    "            duration=info.duration\n",
    "            start=0\n",
    "            for end in range(int(self.sample_rate*self.audio_chunk_len),int(duration*self.sample_rate),int(self.sample_rate*self.audio_chunk_len)):\n",
    "                if not  end-start<self.audio_chunk_len*self.sample_rate:\n",
    "                    files.append({\"path\":file,\"start\":start,'end':end})\n",
    "                start=end\n",
    "        print(f\"{len(files)} files loaded\")\n",
    "        return files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_with_start_end)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        files=np.random.choice(self.audio_with_start_end,self.num_spks,replace=False)\n",
    "        x=0\n",
    "        y=[]\n",
    "        for file in files:\n",
    "            path=file['path']\n",
    "            start=file['start']/self.sample_rate\n",
    "            end=file['end']/self.sample_rate\n",
    "            data,_=librosa.load(path,mono=True,offset=start,duration=end-start,sr=self.sample_rate,dtype='float32')\n",
    "            x=x+data\n",
    "            y.append(data.tolist())\n",
    "        x=tf.constant(np.expand_dims(x,axis=0))\n",
    "        y=tf.constant(np.expand_dims(y,axis=1))\n",
    "        return x,y\n",
    "\n",
    "    def generator(self):\n",
    "        for idx in range(self.data_len):\n",
    "            yield self[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def si_sdr_loss(original, predicted,eps=1e-8,loss_type='sisdr'):\n",
    "\n",
    "        original = original - tf.reduce_mean(original, axis=-1, keepdims=True)\n",
    "        predicted = predicted - tf.reduce_mean(predicted, axis=-1, keepdims=True)\n",
    "\n",
    "        dot_product = tf.reduce_sum(original * predicted, axis=-1)\n",
    "\n",
    "        original_norm_sq = tf.reduce_sum(tf.square(original), axis=-1)\n",
    "        scale = dot_product / (original_norm_sq +eps)\n",
    "        s_target = scale[..., tf.newaxis] * original if loss_type == 'sisdr' else original\n",
    "        e_noise = predicted - s_target\n",
    "        s_target_norm_sq = tf.reduce_sum(tf.square(s_target), axis=-1)\n",
    "        e_noise_norm_sq = tf.reduce_sum(tf.square(e_noise), axis=-1)\n",
    "        si_sdr = 10 * tf.math.log(s_target_norm_sq / (e_noise_norm_sq +eps)) / tf.math.log(10.0)\n",
    "\n",
    "        return -si_sdr\n",
    "@tf.function\n",
    "def cdist_si_sdr(A, B,loss_type='sisdr'):\n",
    "        A=tf.squeeze(A,axis=2)\n",
    "        B=tf.squeeze(B,axis=2)\n",
    "        A_expanded = tf.expand_dims(A, axis=-2)\n",
    "        B_expanded = tf.expand_dims(B, axis=-3)\n",
    "        loss = si_sdr_loss(A_expanded, B_expanded,loss_type=loss_type)\n",
    "        max_loss=tf.reduce_max(loss,axis=[1,2])\n",
    "        return tf.reduce_mean(max_loss)\n",
    "        # return max_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder=\"/mnt/d/Programs/Python/PW/projects/asteroid/zip-hindi-2k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8225 files loaded\n",
      "434 files loaded\n",
      "88 files loaded\n"
     ]
    }
   ],
   "source": [
    "train_data_generator=ConvTasNetDataGenerator(folder_path=f\"{audio_folder}/train\",audio_chunk_len=1)\n",
    "test_data_generator=ConvTasNetDataGenerator(folder_path=f\"{audio_folder}/test\",audio_chunk_len=1)\n",
    "val_data_generator=ConvTasNetDataGenerator(folder_path=f\"{audio_folder}/val\",audio_chunk_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=Dataset.from_generator(train_data_generator.generator,\n",
    "                                     output_signature=(\n",
    "                                         tf.TensorSpec(shape=(1,8000),dtype='float32'),\n",
    "                                         tf.TensorSpec(shape=(2,1,8000),dtype='float32')\n",
    "                                     ))\n",
    "test_dataset=Dataset.from_generator(test_data_generator.generator,\n",
    "                                     output_signature=(\n",
    "                                         tf.TensorSpec(shape=(1,8000),dtype='float32'),\n",
    "                                         tf.TensorSpec(shape=(2,1,8000),dtype='float32')\n",
    "                                     ))\n",
    "val_dataset=Dataset.from_generator(val_data_generator.generator,\n",
    "                                     output_signature=(\n",
    "                                         tf.TensorSpec(shape=(1,8000),dtype='float32'),\n",
    "                                         tf.TensorSpec(shape=(2,1,8000),dtype='float32')\n",
    "                                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader=train_dataset.batch(2)\n",
    "test_data_loader=test_dataset.batch(2)\n",
    "val_data_loader=val_dataset.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvTasNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None,1,8000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=cdist_si_sdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"conv_tas_net\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"conv_tas_net\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ separation_block                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparationBlock</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder (\u001b[38;5;33mEncoder\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ separation_block                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mSeparationBlock\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_74 (\u001b[38;5;33mConv1D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (\u001b[38;5;33mDecoder\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data_loader,epochs=2,steps_per_epoch=100,validation_data=val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.random.uniform(shape=(2,2,1,400))\n",
    "y=tf.random.uniform(shape=(2,2,1,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([39.607803, 37.689766], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdist_si_sdr(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
