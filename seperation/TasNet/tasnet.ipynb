{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import os,glob,random\n",
    "import librosa\n",
    "import soundfile as sf  \n",
    "import numpy as np\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,L,N):\n",
    "        super(Encoder,self).__init__()\n",
    "        \"\"\"\n",
    "        L: Number of input channels(number of samples per segment)\n",
    "        N: Number of output channels(number of basis signals)\n",
    "        \"\"\"\n",
    "        self.L = L\n",
    "        self.N = N\n",
    "        self.EPS = 1e-8\n",
    "        self.conv1d_U=nn.Conv1d(in_channels=L,out_channels=N,kernel_size=1,stride=1,bias=False)\n",
    "        self.conv1d_V=nn.Conv1d(in_channels=L,out_channels=N,kernel_size=1,stride=1,bias=False)\n",
    "    \n",
    "    def forward(self,mixture):\n",
    "        \"\"\"\n",
    "        mixture:Tensor of shape [B,K,L] where K are the number of segment being processed at once\n",
    "        output: Tensor of shape [B,K,N] where N are the number of basis signals\n",
    "        \"\"\"\n",
    "        B,K,L=mixture.size()\n",
    "        norm_coef=torch.norm(mixture,p=2,dim=2,keepdim=True)\n",
    "        normed_mixture=mixture/(norm_coef+self.EPS)\n",
    "        normed_mixture=torch.unsqueeze(normed_mixture.view(-1,L),2)\n",
    "        conv=F.relu(self.conv1d_U(normed_mixture))\n",
    "        gate=F.sigmoid(self.conv1d_V(normed_mixture))\n",
    "        mixture_w=conv*gate\n",
    "        mixture_w=mixture_w.view(B,K,self.N)\n",
    "        return mixture_w,norm_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Separator(nn.Module):\n",
    "    def __init__(self,N:int,hidden_size,num_layers,bidirectional=False,nspk=2) -> None:\n",
    "        super(Separator,self).__init__()\n",
    "        self.N=N\n",
    "        self.hidden_size=hidden_size\n",
    "        self.bidirectional=bidirectional\n",
    "        self.num_layers=num_layers\n",
    "        self.nspk=nspk\n",
    "        self.layer_norm=nn.LayerNorm(N)\n",
    "        self.LSTM=nn.LSTM(input_size=N,hidden_size=hidden_size,num_layers=num_layers,bidirectional=bidirectional,batch_first=True)\n",
    "        fc_in_dim=hidden_size*2 if bidirectional else hidden_size\n",
    "        self.fc=nn.Linear(fc_in_dim,nspk*N)\n",
    "    \n",
    "    def forward(self,mixture_w):\n",
    "        \"\"\"\n",
    "        mixture_w: Tensor of shape [B,K,N]\n",
    "        output: Tensor of shape [B,K,nspk,N]\n",
    "        \"\"\"\n",
    "        B,K,N=mixture_w.size()\n",
    "        normed_mixture_w=self.layer_norm(mixture_w)\n",
    "        output,_=self.LSTM(normed_mixture_w)\n",
    "        score=self.fc(output)\n",
    "        score=score.view(B,K,self.nspk,N)\n",
    "        est_mask=F.softmax(score,dim=2)\n",
    "        return est_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,N,L):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.N=N\n",
    "        self.L=L\n",
    "        self.basis_signals=nn.Linear(N,L,bias=False)\n",
    "    \n",
    "    def forward(self,mixture_w,est_mask,norm_coef):\n",
    "        \"\"\"\n",
    "        mixture_w: Tensor of shape [B,K,N]\n",
    "        est_mask: Tensor of shape [B,K,nspk,N]\n",
    "        norm_coef: Tensor of shape [B,K,1]\n",
    "        output: Tensor of shape [B,nspk,K,L]\n",
    "        \"\"\"\n",
    "        source_w=torch.unsqueeze(mixture_w,2)*est_mask\n",
    "        est_source=self.basis_signals(source_w)\n",
    "        norm_coef=torch.unsqueeze(norm_coef,2)\n",
    "        est_source=est_source*norm_coef\n",
    "        est_source=est_source.permute(0,2,1,3).contiguous()\n",
    "        return est_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TasNet(nn.Module):\n",
    "    def __init__(self,L,N,hidden_size,num_layers,bidirectional=False,nspk=2):\n",
    "        super(TasNet,self).__init__()\n",
    "        self.L=L\n",
    "        self.N=N\n",
    "        self.hidden_size=hidden_size\n",
    "        self.num_layers=num_layers\n",
    "        self.bidirectional=bidirectional\n",
    "        self.nspk=nspk\n",
    "        self.encoder=Encoder(L,N)\n",
    "        self.separator=Separator(N,hidden_size,num_layers,bidirectional,nspk)\n",
    "        self.decoder=Decoder(N,L)\n",
    "    \n",
    "    def forward(self,mixture):\n",
    "        mixture_w,norm_coef=self.encoder(mixture)\n",
    "        est_mask=self.separator(mixture_w)\n",
    "        est_source=self.decoder(mixture_w,est_mask,norm_coef)\n",
    "        return est_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self,L:int,K:int,folder_path:str,sample_rate=8000) -> None:\n",
    "        self.L=L\n",
    "        self.K=K\n",
    "        self.folder_path=folder_path\n",
    "        self.sample_rate=sample_rate\n",
    "        self.files=glob.glob(os.path.join(folder_path,'*.wav'))\n",
    "        self.audio_info=self.load_audio_info()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.audio_info['path'])\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        audio_path=self.audio_info['path'][idx]\n",
    "        start=self.audio_info['start'][idx]/self.sample_rate\n",
    "        end=self.audio_info['end'][idx]/self.sample_rate\n",
    "        audio1,_=librosa.load(audio_path,sr=self.sample_rate,mono=True,offset=start,duration=end-start)\n",
    "        # load a random audio from the data\n",
    "        i=random.randint(a=0,b=len(self.audio_info['path'])-2)\n",
    "        while i==idx:\n",
    "            i=random.randint(a=0,b=len(self.audio_info['path'])-2)\n",
    "        \n",
    "        audio_path=self.audio_info['path'][i]\n",
    "        start=self.audio_info['start'][i]/self.sample_rate\n",
    "        end=self.audio_info['end'][i]/self.sample_rate\n",
    "        audio2,_=librosa.load(audio_path,sr=self.sample_rate,mono=True,offset=start,duration=end-start)\n",
    "        mixture=audio1+audio2\n",
    "        mixture=librosa.util.normalize(mixture)\n",
    "        audio1=librosa.util.normalize(audio1)\n",
    "        audio2=librosa.util.normalize(audio2)\n",
    "        mixture=torch.from_numpy(mixture.reshape(self.K,self.L))\n",
    "        sources=torch.from_numpy(np.array([audio1.reshape(self.K,self.L),audio2.reshape(self.K,self.L)]))\n",
    "        return mixture,sources\n",
    "\n",
    "    def load_audio_info(self):\n",
    "        audio_info=dict(path=list(),start=list(),end=list())\n",
    "        for file in self.files:\n",
    "            info=sf.info(os.path.join(self.folder_path,file))\n",
    "            duration=int(info.duration*self.sample_rate)\n",
    "            chunk_length=self.L*self.K\n",
    "            start=0\n",
    "            for i in range(chunk_length,duration,chunk_length):\n",
    "                if(i-start)==chunk_length:\n",
    "                    audio_info['path'].append(info.name)\n",
    "                    audio_info['start'].append(start)\n",
    "                    audio_info['end'].append(i)\n",
    "                    start=i\n",
    "        return audio_info\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=500\n",
    "N=250\n",
    "hidden_size=250\n",
    "num_layers=2\n",
    "bidirectional=False\n",
    "nspk=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=TasNet(L,N,hidden_size,num_layers,bidirectional,nspk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(2,3,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1505000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3, 500])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder=\"/mnt/d/Programs/Python/PW/projects/asteroid/zip-hindi-2k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=AudioDataset(L=500,K=16,folder_path=audio_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 500]), torch.Size([2, 16, 500]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape,dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtatloader=DataLoader(dataset,batch_size=125,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 16, 500]) torch.Size([125, 2, 16, 500])\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for mixture,sources in dtatloader:\n",
    "    mixture=mixture.to(device)\n",
    "    sources=sources.to(device)\n",
    "    print(mixture.shape,sources.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(permutations([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
